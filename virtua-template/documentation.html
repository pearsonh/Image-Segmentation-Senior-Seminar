<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Image Segmentation Comps</title>
    <link rel="stylesheet" href="css/components.css">
    <link rel="stylesheet" href="css/icons.css">
    <link rel="stylesheet" href="css/responsee.css">
    <link rel="stylesheet" href="owl-carousel/owl.carousel.css">
    <link rel="stylesheet" href="owl-carousel/owl.theme.css">
    <link rel="stylesheet" href="css/lightcase.css">
    <!-- CUSTOM STYLE -->
    <link rel="stylesheet" href="css/template-style.css">
    <link href="https://fonts.googleapis.com/css?family=Poppins:100,200,300,400,700,900&amp;subset=latin-ext" rel="stylesheet">
    <script type="text/javascript" src="js/jquery-1.8.3.min.js"></script>
    <script type="text/javascript" src="js/jquery-ui.min.js"></script>
  </head>

  <body class="size-1280">
    <!-- HEADER -->
    <header role="banner" class="position-absolute">
      <!-- Top Navigation -->
      <nav class="background-transparent background-primary-dott full-width sticky">
        <!-- mobile version logo -->
        <div class="logo hide-l hide-xl hide-xxl">
           <a href="index.html" class="logo">
            <!-- Logo Dark Version -->
            <img class="logo-dark" src="img/logo-dark.svg" alt="">
          </a>
        </div>

        <div class="top-nav">
             <ul class="top-ul chevron">
                <li><a href="index.html">Home</a></li>
                <li><a href="about-us.html">About Us</a></li>
                <li><a href="paper.html">Paper</a></li>
                <li><a href="gallery.html">Image Gallery</a></li>
                <li><a href="documentation.html">Code Documentation</a></li>
             </ul>
        </div>
      </nav>
    </header>

    <!-- MAIN -->
    <main role="main">
      <article>
        <!-- Header -->
        <header class="section background-image text-center" style="background-image:url(img/img-05.jpg)">
          <h1 class="animated-element slow text-extra-thin text-white text-s-size-30 text-m-size-40 text-size-50 text-line-height-1 margin-bottom-30 margin-top-130">
            Code Documentation
          </h1>

          <!-- white full width arrow object -->
          <img class="arrow-object" src="img/arrow-object-white.svg" alt="">
        </header>

        <!-- Section 1 -->
        <section class="section-small-padding background-white text-center">
          <div class="line">
            <p>This is the documentation guide for running our algorithms and experimentation methods.
            Our project code can be downloaded here (include zip download).
            The project code contains implementations of our algorithms, evaluation metrics, and other
            miscelaneous parsing and experimentation files.</p>
            <hr class="break background-primary break-small break-center margin-bottom-50">
            <h2 class="text-dark text-size-30 text-m-size-40">Algorithm <b class="text-primary">Implementations</b></h2>
            <h3 class="text-size-20 margin-bottom-10">All methods to run our
                algorithms take in a color PIL image and return a 2D numpy array of segment numbers for each pixel.</h3>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Thresholding </b></h2>
            <h2 class="text-size-20 margin-bottom-10">thresholding.py</h2>
            <p class="text-dark">This file contains our baseline implementation of the thresholding algorithm and helper functions.</p>
            <code class="primary">baseline_thresholding(image)</code><p>Given a color image,
                converts to grayscale and thresholds using a threshold defined by
                the average grayscale value of all pixels, scaled by 1.5.</p>
            <h2 class="text-size-20 margin-bottom-10">multi_threshold.py</h2>
            <p class="text-dark">This file contains our more sophisticated implementation of the thresholding algorithm, which finds a threshold using Otsu's method.</p>
            <code class="primary">otsu_greyspace_thresholding(image)</code><p>Given a color image,
            converts to grayscale and thresholds on a grayscale value histogram using Otsu's method.</p>
            <code class="primary">otsu_multi_greyspace_thresholding(image, segments)</code><p>Given a color image and a number of segments,
            converts to grayscale and thresholds into the specified number of segments
            on a grayscale value histogram using Otsu's method.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Region Growing </b></h2>
            <h2 class="text-size-20 margin-bottom-10">regionGrowing.py</h2>
            <p class="text-dark">This file contains our implementation of the region growing algorithm and helper methods.</p>
            <code class="primary">region_growing(img,seed,threshold)</code><p>Given an image, a seed, and a threshold, perform region growing and output a segmentation.
                The seed is a tuple indicating the seed pixel to start growing out from, and the threshold determines how similar
                pixels must be to the seed to be added to the same region.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Split and Merge</b></h2>
            <h2 class="text-size-20 margin-bottom-10">regionsplit.py</h2>
            <p class="text-dark">This file contains our partial implementation of the split and merge algorithm and helper methods.
            Currently, this algorithm splits correctly but does not merge all regions that should be merged.</p>
            <code class="primary">regionSplitAndMerge(image,threshold)</code><p>Takes in a color PIL image and integer threshold and performs split and merge on that image.
            The integer threshold gives a cutoff for the acceptable level of variance within a region. In our testing,
            a threshold of 450 produced good results.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">K-Means</b></h2>
            <h2 class="text-size-20 margin-bottom-10">kmeans.py</h2>
            <p class="text-dark">This file contains our implementations of several k-means algorithm variants and helper methods.
                We list here only one version of k-means, since our other versions are not fully tested.</p>
            <code class="primary">kmeans(image, seed='random')</code><p>Runs k-means using the elbow method with a maximum k value of 10. The elbow method runs k-means
            with increasing values of k, finding the value of k for which the in-cluster variance no longer significantly decreases.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Watershed</b></h2>
            <h2 class="text-size-20 margin-bottom-10">watershed.py</h2>
            <p class="text-dark">This file contains our naive implementation of the watershed algorithm, as well as a version using wolf pruning, and helper methods.</p>
            <code class="primary">naive_watershed(image,blur=None)</code><p>Runs watershed algorithm on PIL image input, blurring the image first if specified.</p>
            <code class="primary">watershed_with_wolf(image,depththreshold,blur=None)</code><p>Runs the watershed variant with wolf pruning on input image, blurring the image first if specified.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Minimum Cut</b></h2>
            <h2 class="text-size-20 margin-bottom-10">mincut.py</h2>
            <p class="text-dark">This file contains our (probably buggy) implementation of the minimum cut algorithm and helper methods.</p>
            <code class="primary">mincut(img, edge_weight_function, connectivity=12)</code><p>Runs minimum cut algorithm on a PIL image.
            Specify an edge weight function that captures your desired pixel similarity/difference metric, and number of surrounding pixels
            to be connected in the graph (our trials used 12). Two difference metrics are included (see <code>differenceMetricRGBAndDist</code> and <code>differenceMetricRGB</code>),
            or you can create your own.
            These two parameters will impact the exact output of the algorithm.</p>
            <code class="primary">differenceMetricRGBAndDist(coords1, coords2,pixels)</code><p>Compute difference between two pixels at specified coordinates in a numpy array using Euclidean distance between RGB values and Euclidean distance between their locations.</p>
            <code class="primary">differenceMetricRGB(coords1, coords2, pixels)</code><p>Compute difference between two pixels at specified coordinates in a numpy array using Euclidean distance between RGB values.</p>
          </div>
        </section>

        <section class="section-small-padding background-white text-center">
          <div class="line">
            <hr class="break background-primary break-small break-center margin-bottom-50">
            <h2 class="text-dark text-size-30 text-m-size-40">Evaluation Metric <b class="text-primary">Implementations</b></h2>
            <h3 class="text-size-20 margin-bottom-10">Implementations of our region and edge based evaluation metrics.
                Each metric method takes in a 2D numpy array of ground truth segment labels and
                a 2D numpy array of generated segmentation segment labels. Our datasets provide ground truths in different formats, so when evaluating segmentations against ground truths,
            it is necessary to convert these ground truths into a comparable format (see <code>parser.py</code> below).</h3>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-20 margin-bottom-10">eval.py</h2>
            <p class="text-dark">This file contains our evaluation metric methods and helper methods.</p>
            <code class="primary">bde(segmentation,groundtruth)</code><p>Calculate the BDE value for a segmentation and ground truth.</p>
            <code class="primary">region_based_eval(truth,generated)</code><p>Calculates the Jaccard score for a segmentation and ground truth.</p>
          </div>
        </section>

        <section class="section-small-padding background-white text-center">
          <div class="line">
            <hr class="break background-primary break-small break-center margin-bottom-50">
            <h2 class="text-dark text-size-30 text-m-size-40">Miscellaneous <b class="text-primary">Experimentation Methods</b></h2>
            <h3 class="text-size-20 margin-bottom-10">These files contain methods
                for parsing ground truth files from our datasets into 2D numpy arrays,
                running algorithms on batches of files, and evaluating batches of segmentations.</h3>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Ground Truth Parsing</b></h2>
            <h2 class="text-size-20 margin-bottom-10">parser.py</h2>
            <p class="text-dark">This file contains methods to parse a Weizmann or Berkeley ground truth segmentaitons into a 2D numpy array.</p>
            <code class="primary">import_berkeley(filename)</code><p>Given the path to a file containing a Berkeley encoding of a ground truth, return a numpy array version.</p>
            <code class="primary">import_weizmann(filename)</code><p>Given the path to a file containing a Weizmann encoding of a ground truth, return a numpy array version.</p>
            <code class="primary">display_segmentation(image,number_of_segments)</code><p>Given a numpy array version of a segmentation,
                display a grayscale image representation of that segmentation.</p>
          </div>
        </section>

        <section class="section-small-padding background-white">
          <div class="line">
            <h2 class="text-size-30 margin-bottom-10"><b class="text-strong">Testing Scripts</b></h2>
            <h2 class="text-size-20 margin-bottom-10">operations.py</h2>
            <p class="text-dark">This file contains scripts to run a segmentation algorithm on and evaluate a batch of images.</p>
            <code class="primary">evaluate_all_images(dataset,metric,location_segments, location_truths, output_filename)</code><p>
                Given a dataset (WEIZMANN or BERKELEY) and an evaluation metric (BDE or JACCARD),
                run this metric on segmentations from location_segments and location_truths, and
                output results into a CSV file named output_filename.</p>
            <code class="primary">segment_all_images(location, algorithm, output_folder)</code><p>Segment all images in the indicated location folder using the indicated algorithm,
            and save segmentations in indicated output_folder.</p>
          </div>
        </section>

      </article>
    </main>

    <!-- Bottom Footer -->
    <section class="padding-2x background-dark full-width">
      <div class="line">
        <div class="s-12 l-6">
          <p class="text-size-12">Copyright 2019, Vision Design - graphic zoo</p>
        </div>
        <div class="s-12 l-6">
          <a class="right text-size-12 text-primary-hover" href="http://www.myresponsee.com" title="Responsee - lightweight responsive framework">Design and coding<br> by Responsee Team</a>
        </div>
      </div>
    </section>
    <script type="text/javascript" src="js/responsee.js"></script>
    <script type="text/javascript" src="owl-carousel/owl.carousel.js"></script>
    <script type="text/javascript" src="js/template-scripts.js"></script>
  </body>
</html>
